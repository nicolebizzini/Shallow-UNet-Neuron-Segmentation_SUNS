{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#DEMO TRAIN CNN PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "importing config\n",
            "importing config\n",
            "TensorFlow version: 2.12.1\n",
            "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "  - /physical_device:GPU:0 | Tesla V100-SXM2-16GB | CC=(7, 0)\n",
            "GPU sanity check: OK (matmul on /GPU:0)\n"
          ]
        }
      ],
      "source": [
        "# Imports and GPU detection\n",
        "from typing import Any\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import glob\n",
        "import numpy as np\n",
        "import math\n",
        "import h5py\n",
        "from scipy.io import savemat, loadmat\n",
        "import multiprocessing as mp\n",
        "\n",
        "# Ensure the path contains the \"suns\" folder\n",
        "sys.path.insert(1, '../..')\n",
        "\n",
        "# Backend and device selection\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Set which GPU to use. '-1' uses only CPU.\n",
        "\n",
        "# Import config and core SUNS modules\n",
        "from suns import config\n",
        "print(\"importing config\")\n",
        "\n",
        "from suns.PreProcessing.preprocessing_functions import preprocess_video, find_dataset\n",
        "from suns.PreProcessing.generate_masks import generate_masks\n",
        "from suns.train_CNN_params import train_CNN, parameter_optimization_cross_validation\n",
        "\n",
        "# TensorFlow GPU setup and sanity check\n",
        "import tensorflow as tf\n",
        "\n",
        "tf_version = int(tf.__version__[0])\n",
        "if tf_version == 1:\n",
        "    tf_config = tf.ConfigProto()\n",
        "    tf_config.gpu_options.allow_growth = True\n",
        "    sess = tf.Session(config=tf_config)\n",
        "else:  # TensorFlow 2.x\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "    # ---- GPU visibility and quick verification ----\n",
        "    print(f\"TensorFlow version: {tf.__version__}\")\n",
        "    print(\"Visible GPUs:\", gpus)\n",
        "    if gpus:\n",
        "        try:\n",
        "            for g in gpus:\n",
        "                det = tf.config.experimental.get_device_details(g)\n",
        "                name = det.get('device_name', 'Unknown GPU')\n",
        "                cc = det.get('compute_capability', 'n/a')\n",
        "                print(f\"  - {g.name} | {name} | CC={cc}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        # Small op to confirm /GPU:0 executes\n",
        "        try:\n",
        "            with tf.device('/GPU:0'):\n",
        "                a = tf.random.uniform((1024, 1024))\n",
        "                b = tf.random.uniform((1024, 1024))\n",
        "                _ = tf.matmul(a, b)\n",
        "            print('GPU sanity check: OK (matmul on /GPU:0)')\n",
        "        except Exception as e:\n",
        "            print('GPU sanity check failed, training may run on CPU:', repr(e))\n",
        "    else:\n",
        "        print('No GPU detected by TensorFlow; training will run on CPU.')\n",
        "\n",
        "# Optional: enable device placement logging (verbose)\n",
        "LOG_DEVICE_PLACEMENT = False\n",
        "if LOG_DEVICE_PLACEMENT and tf_version != 1:\n",
        "    try:\n",
        "        tf.debugging.set_log_device_placement(True)\n",
        "    except Exception:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "list_Exp_ID: ['mouse7_773', 'mouse7_774', 'mouse7_775', 'mouse7_776']\n",
            "dir_video: /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new\n",
            "dir_GTMasks: /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/GT Masks/FinalMasks_\n"
          ]
        }
      ],
      "source": [
        "# Dataset IDs and directories\n",
        "list_Exp_ID = config.EXP_ID_SETS[config.ACTIVE_EXP_SET]\n",
        "dir_video = config.DATAFOLDER_SETS[config.ACTIVE_EXP_SET]\n",
        "# folder of the \".mat\" files storing the GT masks in sparse 2D matrices. 'FinalMasks_' is a prefix of the file names.\n",
        "dir_GTMasks = os.path.join(dir_video, 'GT Masks', 'FinalMasks_')\n",
        "\n",
        "print(\"list_Exp_ID:\", list_Exp_ID)\n",
        "print(\"dir_video:\", dir_video)\n",
        "print(\"dir_GTMasks:\", dir_GTMasks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Video parameters: frame rate and magnification\n",
        "rate_hz = config.RATE_HZ[config.ACTIVE_EXP_SET]\n",
        "Mag = config.MAG[config.ACTIVE_EXP_SET]\n",
        "\n",
        "print(\"rate_hz:\", rate_hz)\n",
        "print(\"Mag:\", Mag)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-processing parameters\n",
        "# Spatial Gaussian filter size (in pixels)\n",
        "gauss_filt_size = 50 * Mag\n",
        "# Number of frames used to calculate median and median-based std\n",
        "num_median_approx = 1000\n",
        "\n",
        "# Temporal filter kernel using a single exponential decay function\n",
        "# 6f: 0.8, 6s: 1.25 (unit: second)\n",
        "decay = 1.25\n",
        "leng_tf = np.ceil(rate_hz * decay) + 1\n",
        "Poisson_filt = np.exp(-np.arange(leng_tf) / rate_hz / decay)\n",
        "Poisson_filt = (Poisson_filt / Poisson_filt.sum()).astype('float32')\n",
        "\n",
        "print(\"gauss_filt_size:\", gauss_filt_size)\n",
        "print(\"num_median_approx:\", num_median_approx)\n",
        "print(\"Poisson_filt length:\", Poisson_filt.size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "thred_std = 3 # SNR threshold to determine when neurons are active\n",
        "num_train_per = 1280  # Number of frames per video used for training\n",
        "NO_OF_EPOCHS = 120  # Number of epochs used for training\n",
        "batch_size_eval = 100  # Batch size in CNN inference\n",
        "list_thred_ratio = [thred_std]  # A list of SNR threshold values\n",
        "\n",
        "print(\"thred_std:\", thred_std)\n",
        "print(\"num_train_per:\", num_train_per)\n",
        "print(\"NO_OF_EPOCHS:\", NO_OF_EPOCHS)\n",
        "print(\"batch_size_eval:\", batch_size_eval)\n",
        "print(\"list_thred_ratio:\", list_thred_ratio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Processing options\n",
        "useSF = False  # Spatial filtering in pre-processing\n",
        "useTF = True   # Temporal filtering in pre-processing\n",
        "useSNR = True  # Pixel-by-pixel SNR normalization filtering in pre-processing\n",
        "med_subtract = False  # Subtract spatial median before temporal filtering (only if no spatial filtering)\n",
        "prealloc = False  # Pre-allocate memory (faster, higher memory usage). Not needed for training.\n",
        "useWT = False  # Use additional watershed\n",
        "load_exist = False  # Use temp files already saved in folders\n",
        "use_validation = True  # Use validation set outside the training set\n",
        "useMP = False  # Use multiprocessing to speed up\n",
        "BATCH_SIZE = 20  # Batch size for training\n",
        "\n",
        "# Cross-validation strategy: \"leave_one_out\", \"train_1_test_rest\", or \"use_all\"\n",
        "cross_validation = \"leave_one_out\"\n",
        "\n",
        "# Parameters of the loss function\n",
        "Params_loss = {\"DL\": 1, \"BCE\": 20, \"FL\": 0, \"gamma\": 1, \"alpha\": 0.25}\n",
        "\n",
        "print(\"Options:\", {\n",
        "    'useSF': useSF,\n",
        "    'useTF': useTF,\n",
        "    'useSNR': useSNR,\n",
        "    'med_subtract': med_subtract,\n",
        "    'prealloc': prealloc,\n",
        "    'useWT': useWT,\n",
        "    'load_exist': load_exist,\n",
        "    'use_validation': use_validation,\n",
        "    'useMP': useMP,\n",
        "    'BATCH_SIZE': BATCH_SIZE,\n",
        "    'cross_validation': cross_validation,\n",
        "    'Params_loss': Params_loss,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN training and parameter optimization\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# ---- Output directories ----\n",
        "dir_parent = os.path.join(dir_video, config.OUTPUT_FOLDER[config.ACTIVE_EXP_SET])\n",
        "dir_network_input = os.path.join(dir_parent, 'network_input')\n",
        "dir_mask = os.path.join(dir_parent, f'temporal_masks({thred_std})')\n",
        "weights_path = os.path.join(dir_parent, 'Weights')\n",
        "training_output_path = os.path.join(dir_parent, 'training output')\n",
        "dir_output = os.path.join(dir_parent, 'output_masks')\n",
        "dir_temp = os.path.join(dir_parent, 'temp')\n",
        "\n",
        "for d in [dir_network_input, weights_path, training_output_path, dir_output, dir_temp]:\n",
        "    if not os.path.exists(d):\n",
        "        os.makedirs(d)\n",
        "\n",
        "# ---- Get and check video dimensions ----\n",
        "nvideo = len(list_Exp_ID)\n",
        "list_Dimens = np.zeros((nvideo, 3), dtype='uint16')\n",
        "for (eid, Exp_ID) in enumerate(list_Exp_ID):\n",
        "    h5_video = os.path.join(dir_video, Exp_ID + '.h5')\n",
        "    h5_file = h5py.File(h5_video, 'r')\n",
        "    dset = find_dataset(h5_file)\n",
        "    list_Dimens[eid] = h5_file[dset].shape\n",
        "    h5_file.close()\n",
        "\n",
        "nframes = np.unique(list_Dimens[:, 0])\n",
        "Lx = np.unique(list_Dimens[:, 1])\n",
        "Ly = np.unique(list_Dimens[:, 2])\n",
        "if len(Lx) * len(Ly) != 1:\n",
        "    raise ValueError('The lateral dimensions of all the training videos must be the same in this version.')\n",
        "\n",
        "nframes = nframes.min()\n",
        "rows = Lx[0]\n",
        "cols = Ly[0]\n",
        "\n",
        "rowspad = int(np.ceil(rows / 8) * 8)\n",
        "colspad = int(np.ceil(cols / 8) * 8)\n",
        "num_total = int(nframes - Poisson_filt.size + 1)\n",
        "\n",
        "# ---- Post-processing hyper-parameters to optimize ----\n",
        "list_minArea = list(range(30, 85, 5))\n",
        "list_avgArea = [177]\n",
        "list_thresh_pmap = list(range(130, 235, 10))\n",
        "thresh_mask = 0.5\n",
        "thresh_COM0 = 2\n",
        "list_thresh_COM = list(np.arange(4, 9, 1))\n",
        "list_thresh_IOU = [0.5]\n",
        "list_cons = list(range(1, 8, 1))\n",
        "\n",
        "# Adjust units according to magnification and frame rate differences\n",
        "list_minArea = list(np.round(np.array(list_minArea) * Mag ** 2))\n",
        "list_avgArea = list(np.round(np.array(list_avgArea) * Mag ** 2))\n",
        "thresh_COM0 = thresh_COM0 * Mag\n",
        "list_thresh_COM = list(np.array(list_thresh_COM) * Mag)\n",
        "# Optionally adjust list_cons for different frame rates (kept as-is, like script)\n",
        "\n",
        "# ---- Pack parameter dictionaries ----\n",
        "Params_pre = {\n",
        "    'gauss_filt_size': gauss_filt_size,\n",
        "    'num_median_approx': num_median_approx,\n",
        "    'Poisson_filt': Poisson_filt,\n",
        "}\n",
        "Params_set = {\n",
        "    'list_minArea': list_minArea,\n",
        "    'list_avgArea': list_avgArea,\n",
        "    'list_thresh_pmap': list_thresh_pmap,\n",
        "    'thresh_COM0': thresh_COM0,\n",
        "    'list_thresh_COM': list_thresh_COM,\n",
        "    'list_thresh_IOU': list_thresh_IOU,\n",
        "    'thresh_mask': thresh_mask,\n",
        "    'list_cons': list_cons,\n",
        "}\n",
        "print(\"Params_set:\", Params_set)\n",
        "\n",
        "# ---- Pre-processing for training ----\n",
        "for Exp_ID in list_Exp_ID:\n",
        "    # Pre-process video\n",
        "    video_input, _ = preprocess_video(\n",
        "        dir_video,\n",
        "        Exp_ID,\n",
        "        Params_pre,\n",
        "        dir_network_input,\n",
        "        useSF=useSF,\n",
        "        useTF=useTF,\n",
        "        useSNR=useSNR,\n",
        "        med_subtract=med_subtract,\n",
        "        prealloc=prealloc,\n",
        "    )\n",
        "\n",
        "    # Determine active neurons in all frames using FISSA (debug and validation inside generate_masks)\n",
        "    file_mask = dir_GTMasks + Exp_ID + '.mat'\n",
        "    try:\n",
        "        import fissa  # type: ignore\n",
        "        print(f\"[DEBUG] FISSA import OK; version={getattr(fissa, '__version__', 'unknown')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[DEBUG] FISSA import failed at call site: {e}\")\n",
        "\n",
        "    print(f\"[DEBUG] Calling generate_masks for Exp_ID={Exp_ID} with masks={file_mask}\")\n",
        "    generate_masks(video_input, file_mask, list_thred_ratio, dir_parent, Exp_ID)\n",
        "    print(f\"[DEBUG] Finished generate_masks for Exp_ID={Exp_ID}\")\n",
        "    del video_input\n",
        "\n",
        "# ---- CNN training (cross-validation) ----\n",
        "if cross_validation == \"use_all\":\n",
        "    list_CV = [nvideo]\n",
        "else:\n",
        "    list_CV = list(range(0, nvideo))\n",
        "\n",
        "for CV in list_CV:\n",
        "    if cross_validation == \"leave_one_out\":\n",
        "        list_Exp_ID_train = list_Exp_ID.copy()\n",
        "        list_Exp_ID_val = [list_Exp_ID_train.pop(CV)]\n",
        "    elif cross_validation == \"train_1_test_rest\":\n",
        "        list_Exp_ID_val = list_Exp_ID.copy()\n",
        "        list_Exp_ID_train = [list_Exp_ID_val.pop(CV)]\n",
        "    elif cross_validation == \"use_all\":\n",
        "        use_validation = False\n",
        "        list_Exp_ID_train = list_Exp_ID.copy()\n",
        "    else:\n",
        "        raise RuntimeError('wrong \"cross_validation\"')\n",
        "\n",
        "    if not use_validation:\n",
        "        list_Exp_ID_val = None\n",
        "\n",
        "    file_CNN = os.path.join(weights_path, f'Model_CV{CV}.h5')\n",
        "    results = train_CNN(\n",
        "        dir_network_input,\n",
        "        dir_mask,\n",
        "        file_CNN,\n",
        "        list_Exp_ID_train,\n",
        "        list_Exp_ID_val,\n",
        "        BATCH_SIZE,\n",
        "        NO_OF_EPOCHS,\n",
        "        num_train_per,\n",
        "        num_total,\n",
        "        (rowspad, colspad),\n",
        "        Params_loss,\n",
        "    )\n",
        "\n",
        "    # Save training and validation loss after each epoch\n",
        "    with h5py.File(os.path.join(training_output_path, f\"training_output_CV{CV}.h5\"), \"w\") as f:\n",
        "        f.create_dataset(\"loss\", data=results.history['loss'])\n",
        "        f.create_dataset(\"dice_loss\", data=results.history['dice_loss'])\n",
        "        if use_validation:\n",
        "            f.create_dataset(\"val_loss\", data=results.history['val_loss'])\n",
        "            f.create_dataset(\"val_dice_loss\", data=results.history['val_dice_loss'])\n",
        "\n",
        "# ---- Parameter optimization across CV ----\n",
        "parameter_optimization_cross_validation(\n",
        "    cross_validation,\n",
        "    list_Exp_ID,\n",
        "    Params_set,\n",
        "    (rows, cols),\n",
        "    dir_network_input,\n",
        "    weights_path,\n",
        "    dir_GTMasks,\n",
        "    dir_temp,\n",
        "    dir_output,\n",
        "    batch_size_eval,\n",
        "    useWT=useWT,\n",
        "    useMP=useMP,\n",
        "    load_exist=load_exist,\n",
        ")\n",
        "\n",
        "print(\"Pipeline complete.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TensorFlow 2.12",
      "language": "python",
      "name": "tensorflow-2.12"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
