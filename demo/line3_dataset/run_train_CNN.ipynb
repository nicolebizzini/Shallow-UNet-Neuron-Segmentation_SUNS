{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CWD: /gpfs/data/shohamlab/nicole/code/SUNS_nicole\n",
            "Running: /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/train_3_test_1/demo_train_CNN_params.py\n",
            "importing config\n",
            "importing config\n",
            "TensorFlow version: 2.12.1\n",
            "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "  - /physical_device:GPU:0 | Tesla V100-SXM2-16GB | CC=(7, 0)\n",
            "GPU sanity check: OK (matmul on /GPU:0)\n",
            "{'list_minArea': [5.0, 6.0, 6.0, 7.0, 8.0, 9.0, 10.0, 10.0, 11.0, 12.0, 13.0], 'list_avgArea': [28.0], 'list_thresh_pmap': [110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230], 'thresh_COM0': 0.798, 'list_thresh_COM': [1.596, 1.995, 2.394, 2.793, 3.192], 'list_thresh_IOU': [0.5], 'thresh_mask': 0.3, 'list_cons': [1, 2, 3, 4, 5, 6, 7]}\n",
            "256 256 1600 -> 256 256 1600\n",
            "FFT planning: 0.36323046684265137 s\n",
            "Initialization: 0.012060880661010742 s\n",
            "data loading: 497.8561153411865 s\n",
            "spatial filtering: 12.825438261032104 s\n",
            "    Log time: 5.495022296905518 s\n",
            "    FFT1 time: 1.1246123313903809 s\n",
            "    Mask time: 0.23134589195251465 s\n",
            "    FFT2 time: 1.291471242904663 s\n",
            "    Exp time: 4.682986497879028 s\n",
            "temporal filtering: 6.590319633483887 s\n",
            "median computation: 11.829156398773193 s\n",
            "normalization: 0.557671070098877 s\n",
            "total per frame: 19.877598136663437 ms\n",
            "Network_input saving: 0.9485559463500977 s\n",
            "[generate_masks] Using sparse GT: /gpfs/data/shohamlab/nicole/code/SUNS_nicole/demo/line3_dataset/GT Masks/FinalMasks_mouse3_sparse.mat → n=713\n",
            "[generate_masks] network_input: (1595, 256, 256)  rois: (713, 256, 256) (ncells=713, rows=256, cols=256)\n",
            "[generate_masks] Trying FISSA with roi_list of length 713; first ROI shape=(256, 256)\n",
            "Doing region growing and data extraction....\n",
            "FISSA unavailable or ROI format unsupported (setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.); falling back to simple ROI traces.\n",
            "Mask creation: 16.133260250091553 s\n",
            "Mask saving: 0.2384328842163086 s\n",
            "256 256 1600 -> 256 256 1600\n",
            "FFT planning: 0.5354189872741699 s\n",
            "Initialization: 0.1372838020324707 s\n",
            "data loading: 596.4860134124756 s\n",
            "spatial filtering: 11.502869129180908 s\n",
            "    Log time: 5.778069496154785 s\n",
            "    FFT1 time: 1.1249291896820068 s\n",
            "    Mask time: 0.22944283485412598 s\n",
            "    FFT2 time: 1.3040320873260498 s\n",
            "    Exp time: 3.0663955211639404 s\n",
            "temporal filtering: 3.795536756515503 s\n",
            "median computation: 6.306366920471191 s\n",
            "normalization: 0.30593013763427734 s\n",
            "total per frame: 13.694963306188583 ms\n",
            "Network_input saving: 0.6515922546386719 s\n",
            "[generate_masks] Using sparse GT: /gpfs/data/shohamlab/nicole/code/SUNS_nicole/demo/line3_dataset/GT Masks/FinalMasks_mouse6_sparse.mat → n=968\n",
            "[generate_masks] network_input: (1595, 256, 256)  rois: (968, 256, 256) (ncells=968, rows=256, cols=256)\n",
            "[generate_masks] Trying FISSA with roi_list of length 968; first ROI shape=(256, 256)\n",
            "Doing region growing and data extraction....\n",
            "FISSA unavailable or ROI format unsupported (setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.); falling back to simple ROI traces.\n",
            "Mask creation: 4.289157152175903 s\n",
            "Mask saving: 0.16754555702209473 s\n",
            "256 256 1600 -> 256 256 1600\n",
            "FFT planning: 0.3135213851928711 s\n",
            "Initialization: 0.0010330677032470703 s\n",
            "data loading: 485.78341341018677 s\n",
            "spatial filtering: 11.510022640228271 s\n",
            "    Log time: 5.869967460632324 s\n",
            "    FFT1 time: 1.0837700366973877 s\n",
            "    Mask time: 0.25680041313171387 s\n",
            "    FFT2 time: 1.2563815116882324 s\n",
            "    Exp time: 3.0431032180786133 s\n",
            "temporal filtering: 3.77006196975708 s\n",
            "median computation: 6.3618457317352295 s\n",
            "normalization: 0.3276243209838867 s\n",
            "total per frame: 13.731517791748047 ms\n",
            "Network_input saving: 0.6981508731842041 s\n",
            "[generate_masks] Using sparse GT: /gpfs/data/shohamlab/nicole/code/SUNS_nicole/demo/line3_dataset/GT Masks/FinalMasks_mouse7_sparse.mat → n=1104\n",
            "[generate_masks] network_input: (1595, 256, 256)  rois: (1104, 256, 256) (ncells=1104, rows=256, cols=256)\n",
            "[generate_masks] Trying FISSA with roi_list of length 1104; first ROI shape=(256, 256)\n",
            "Doing region growing and data extraction....\n",
            "FISSA unavailable or ROI format unsupported (setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.); falling back to simple ROI traces.\n",
            "Mask creation: 12.50931978225708 s\n",
            "Mask saving: 0.23270583152770996 s\n",
            "256 256 1600 -> 256 256 1600\n",
            "FFT planning: 0.40339088439941406 s\n",
            "Initialization: 0.0012264251708984375 s\n",
            "data loading: 394.9424991607666 s\n",
            "spatial filtering: 8.340243816375732 s\n",
            "    Log time: 3.861771821975708 s\n",
            "    FFT1 time: 1.0762321949005127 s\n",
            "    Mask time: 0.1725752353668213 s\n",
            "    FFT2 time: 1.190267562866211 s\n",
            "    Exp time: 2.0393970012664795 s\n",
            "temporal filtering: 2.5051965713500977 s\n",
            "median computation: 4.3456737995147705 s\n",
            "normalization: 0.19977593421936035 s\n",
            "total per frame: 9.619791060686111 ms\n",
            "Network_input saving: 0.7507805824279785 s\n",
            "[generate_masks] Using sparse GT: /gpfs/data/shohamlab/nicole/code/SUNS_nicole/demo/line3_dataset/GT Masks/FinalMasks_mouse12_sparse.mat → n=454\n",
            "[generate_masks] network_input: (1595, 256, 256)  rois: (454, 256, 256) (ncells=454, rows=256, cols=256)\n",
            "[generate_masks] Trying FISSA with roi_list of length 454; first ROI shape=(256, 256)\n",
            "Doing region growing and data extraction....\n",
            "FISSA unavailable or ROI format unsupported (setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.); falling back to simple ROI traces.\n",
            "Mask creation: 2.0518832206726074 s\n",
            "Mask saving: 0.26216650009155273 s\n",
            "Loading training images and masks.\n",
            "flips = True, rotate = True\n",
            "Epoch 1/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 4.7433 - dice_loss: 0.8724flips = False, rotate = False\n",
            "\n",
            "\n",
            "The average loss for epoch 0 is  4.7201.\n",
            "112/112 [==============================] - 11s 41ms/step - loss: 4.7201 - dice_loss: 0.8706 - val_loss: 2.1495 - val_dice_loss: 0.6421 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.9757 - dice_loss: 0.6770\n",
            "\n",
            "The average loss for epoch 1 is  1.9741.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.9741 - dice_loss: 0.6768 - val_loss: 1.9834 - val_dice_loss: 0.6269 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.7764 - dice_loss: 0.6410\n",
            "\n",
            "The average loss for epoch 2 is  1.7748.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.7748 - dice_loss: 0.6414 - val_loss: 2.0000 - val_dice_loss: 0.6334 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6879 - dice_loss: 0.6295\n",
            "\n",
            "The average loss for epoch 3 is  1.6872.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6872 - dice_loss: 0.6295 - val_loss: 1.8887 - val_dice_loss: 0.6063 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "112/112 [==============================] - ETA: 0s - loss: 1.6254 - dice_loss: 0.6160\n",
            "\n",
            "The average loss for epoch 4 is  1.6254.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6254 - dice_loss: 0.6160 - val_loss: 1.8708 - val_dice_loss: 0.5969 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.5739 - dice_loss: 0.6071\n",
            "\n",
            "The average loss for epoch 5 is  1.5757.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.5757 - dice_loss: 0.6066 - val_loss: 1.8333 - val_dice_loss: 0.6001 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.5366 - dice_loss: 0.5986\n",
            "\n",
            "The average loss for epoch 6 is  1.5368.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.5368 - dice_loss: 0.5985 - val_loss: 1.8754 - val_dice_loss: 0.5922 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.5049 - dice_loss: 0.5928\n",
            "\n",
            "The average loss for epoch 7 is  1.5052.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.5052 - dice_loss: 0.5927 - val_loss: 1.9191 - val_dice_loss: 0.6204 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4823 - dice_loss: 0.5872\n",
            "\n",
            "The average loss for epoch 8 is  1.4828.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.4828 - dice_loss: 0.5873 - val_loss: 1.9316 - val_dice_loss: 0.6083 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4620 - dice_loss: 0.5849\n",
            "\n",
            "The average loss for epoch 9 is  1.4614.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.4614 - dice_loss: 0.5850 - val_loss: 1.7992 - val_dice_loss: 0.5849 - lr: 0.0010\n",
            "Epoch 11/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4437 - dice_loss: 0.5799\n",
            "\n",
            "The average loss for epoch 10 is  1.4432.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 1.4432 - dice_loss: 0.5799 - val_loss: 1.8237 - val_dice_loss: 0.5830 - lr: 0.0010\n",
            "Epoch 12/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4311 - dice_loss: 0.5772\n",
            "\n",
            "The average loss for epoch 11 is  1.4304.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.4304 - dice_loss: 0.5773 - val_loss: 1.8144 - val_dice_loss: 0.5707 - lr: 0.0010\n",
            "Epoch 13/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4191 - dice_loss: 0.5758\n",
            "\n",
            "The average loss for epoch 12 is  1.4187.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 1.4187 - dice_loss: 0.5756 - val_loss: 1.9234 - val_dice_loss: 0.6193 - lr: 0.0010\n",
            "Epoch 14/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4045 - dice_loss: 0.5720\n",
            "\n",
            "The average loss for epoch 13 is  1.4043.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.4043 - dice_loss: 0.5719 - val_loss: 1.8034 - val_dice_loss: 0.5774 - lr: 0.0010\n",
            "Epoch 15/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3961 - dice_loss: 0.5698\n",
            "\n",
            "The average loss for epoch 14 is  1.3943.\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 1.3943 - dice_loss: 0.5700 - val_loss: 1.8760 - val_dice_loss: 0.6014 - lr: 0.0010\n",
            "Epoch 16/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3847 - dice_loss: 0.5675\n",
            "\n",
            "The average loss for epoch 15 is  1.3842.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3842 - dice_loss: 0.5673 - val_loss: 1.7788 - val_dice_loss: 0.5727 - lr: 5.0000e-04\n",
            "Epoch 17/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3764 - dice_loss: 0.5664\n",
            "\n",
            "The average loss for epoch 16 is  1.3783.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3783 - dice_loss: 0.5662 - val_loss: 1.8189 - val_dice_loss: 0.5811 - lr: 5.0000e-04\n",
            "Epoch 18/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3713 - dice_loss: 0.5638\n",
            "\n",
            "The average loss for epoch 17 is  1.3706.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.3706 - dice_loss: 0.5641 - val_loss: 1.8540 - val_dice_loss: 0.5912 - lr: 5.0000e-04\n",
            "Epoch 19/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3655 - dice_loss: 0.5641\n",
            "\n",
            "The average loss for epoch 18 is  1.3676.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.3676 - dice_loss: 0.5643 - val_loss: 1.7767 - val_dice_loss: 0.5717 - lr: 5.0000e-04\n",
            "Epoch 20/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3595 - dice_loss: 0.5621\n",
            "\n",
            "The average loss for epoch 19 is  1.3594.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3594 - dice_loss: 0.5622 - val_loss: 1.8121 - val_dice_loss: 0.5701 - lr: 5.0000e-04\n",
            "Epoch 21/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3577 - dice_loss: 0.5598\n",
            "\n",
            "The average loss for epoch 20 is  1.3557.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3557 - dice_loss: 0.5598 - val_loss: 1.7677 - val_dice_loss: 0.5572 - lr: 5.0000e-04\n",
            "Epoch 22/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3511 - dice_loss: 0.5590\n",
            "\n",
            "The average loss for epoch 21 is  1.3495.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3495 - dice_loss: 0.5593 - val_loss: 1.7996 - val_dice_loss: 0.5685 - lr: 5.0000e-04\n",
            "Epoch 23/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3409 - dice_loss: 0.5563\n",
            "\n",
            "The average loss for epoch 22 is  1.3442.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3442 - dice_loss: 0.5563 - val_loss: 1.8128 - val_dice_loss: 0.5932 - lr: 5.0000e-04\n",
            "Epoch 24/60\n",
            "112/112 [==============================] - ETA: 0s - loss: 1.3396 - dice_loss: 0.5565\n",
            "\n",
            "The average loss for epoch 23 is  1.3396.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3396 - dice_loss: 0.5565 - val_loss: 1.7673 - val_dice_loss: 0.5619 - lr: 5.0000e-04\n",
            "Epoch 25/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3303 - dice_loss: 0.5540\n",
            "\n",
            "The average loss for epoch 24 is  1.3307.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3307 - dice_loss: 0.5539 - val_loss: 1.8029 - val_dice_loss: 0.5921 - lr: 5.0000e-04\n",
            "Epoch 26/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3300 - dice_loss: 0.5533\n",
            "\n",
            "The average loss for epoch 25 is  1.3283.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 1.3283 - dice_loss: 0.5537 - val_loss: 1.7854 - val_dice_loss: 0.5748 - lr: 5.0000e-04\n",
            "Epoch 27/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3205 - dice_loss: 0.5496\n",
            "\n",
            "The average loss for epoch 26 is  1.3216.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 1.3216 - dice_loss: 0.5498 - val_loss: 1.8468 - val_dice_loss: 0.5790 - lr: 5.0000e-04\n",
            "Epoch 28/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3236 - dice_loss: 0.5513\n",
            "\n",
            "The average loss for epoch 27 is  1.3205.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3205 - dice_loss: 0.5510 - val_loss: 1.8025 - val_dice_loss: 0.5722 - lr: 5.0000e-04\n",
            "Epoch 29/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3164 - dice_loss: 0.5493\n",
            "\n",
            "The average loss for epoch 28 is  1.3150.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3150 - dice_loss: 0.5495 - val_loss: 1.7631 - val_dice_loss: 0.5683 - lr: 5.0000e-04\n",
            "Epoch 30/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3076 - dice_loss: 0.5489\n",
            "\n",
            "The average loss for epoch 29 is  1.3092.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3092 - dice_loss: 0.5489 - val_loss: 1.7744 - val_dice_loss: 0.5583 - lr: 5.0000e-04\n",
            "Epoch 31/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3042 - dice_loss: 0.5473\n",
            "\n",
            "The average loss for epoch 30 is  1.3037.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3037 - dice_loss: 0.5473 - val_loss: 1.7778 - val_dice_loss: 0.5529 - lr: 5.0000e-04\n",
            "Epoch 32/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3020 - dice_loss: 0.5470\n",
            "\n",
            "The average loss for epoch 31 is  1.3027.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3027 - dice_loss: 0.5467 - val_loss: 1.7621 - val_dice_loss: 0.5456 - lr: 5.0000e-04\n",
            "Epoch 33/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2961 - dice_loss: 0.5451\n",
            "\n",
            "The average loss for epoch 32 is  1.2969.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2969 - dice_loss: 0.5450 - val_loss: 1.7071 - val_dice_loss: 0.5621 - lr: 5.0000e-04\n",
            "Epoch 34/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2979 - dice_loss: 0.5463\n",
            "\n",
            "The average loss for epoch 33 is  1.2978.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2978 - dice_loss: 0.5463 - val_loss: 1.7802 - val_dice_loss: 0.5819 - lr: 5.0000e-04\n",
            "Epoch 35/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2924 - dice_loss: 0.5458\n",
            "\n",
            "The average loss for epoch 34 is  1.2932.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2932 - dice_loss: 0.5458 - val_loss: 1.6960 - val_dice_loss: 0.5394 - lr: 5.0000e-04\n",
            "Epoch 36/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2854 - dice_loss: 0.5436\n",
            "\n",
            "The average loss for epoch 35 is  1.2874.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2874 - dice_loss: 0.5438 - val_loss: 1.7666 - val_dice_loss: 0.5626 - lr: 5.0000e-04\n",
            "Epoch 37/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2852 - dice_loss: 0.5439\n",
            "\n",
            "The average loss for epoch 36 is  1.2876.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2876 - dice_loss: 0.5437 - val_loss: 1.7996 - val_dice_loss: 0.5693 - lr: 5.0000e-04\n",
            "Epoch 38/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2832 - dice_loss: 0.5427\n",
            "\n",
            "The average loss for epoch 37 is  1.2817.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 1.2817 - dice_loss: 0.5425 - val_loss: 1.8031 - val_dice_loss: 0.5667 - lr: 5.0000e-04\n",
            "Epoch 39/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2828 - dice_loss: 0.5439\n",
            "\n",
            "The average loss for epoch 38 is  1.2817.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2817 - dice_loss: 0.5443 - val_loss: 1.7633 - val_dice_loss: 0.5590 - lr: 5.0000e-04\n",
            "Epoch 40/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2739 - dice_loss: 0.5422\n",
            "\n",
            "The average loss for epoch 39 is  1.2764.\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2764 - dice_loss: 0.5423 - val_loss: 1.7667 - val_dice_loss: 0.5693 - lr: 5.0000e-04\n",
            "Epoch 41/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2785 - dice_loss: 0.5419\n",
            "\n",
            "The average loss for epoch 40 is  1.2766.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2766 - dice_loss: 0.5421 - val_loss: 1.7852 - val_dice_loss: 0.5523 - lr: 2.5000e-04\n",
            "Epoch 42/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2732 - dice_loss: 0.5397\n",
            "\n",
            "The average loss for epoch 41 is  1.2729.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 1.2729 - dice_loss: 0.5399 - val_loss: 1.7940 - val_dice_loss: 0.5667 - lr: 2.5000e-04\n",
            "Epoch 43/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2735 - dice_loss: 0.5414\n",
            "\n",
            "The average loss for epoch 42 is  1.2725.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2725 - dice_loss: 0.5415 - val_loss: 1.7294 - val_dice_loss: 0.5645 - lr: 2.5000e-04\n",
            "Epoch 44/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2711 - dice_loss: 0.5402\n",
            "\n",
            "The average loss for epoch 43 is  1.2695.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2695 - dice_loss: 0.5404 - val_loss: 1.7695 - val_dice_loss: 0.5433 - lr: 2.5000e-04\n",
            "Epoch 45/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2659 - dice_loss: 0.5395\n",
            "\n",
            "The average loss for epoch 44 is  1.2675.\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2675 - dice_loss: 0.5393 - val_loss: 1.7629 - val_dice_loss: 0.5499 - lr: 2.5000e-04\n",
            "Epoch 46/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2682 - dice_loss: 0.5409\n",
            "\n",
            "The average loss for epoch 45 is  1.2694.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2694 - dice_loss: 0.5406 - val_loss: 1.7413 - val_dice_loss: 0.5417 - lr: 1.2500e-04\n",
            "Epoch 47/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.2674 - dice_loss: 0.5392\n",
            "\n",
            "The average loss for epoch 46 is  1.2681.\n",
            "Restoring model weights from the end of the best epoch: 35.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.2681 - dice_loss: 0.5390 - val_loss: 1.7188 - val_dice_loss: 0.5514 - lr: 1.2500e-04\n",
            "Epoch 47: early stopping\n",
            "Loading training images and masks.\n",
            "flips = True, rotate = True\n",
            "Epoch 1/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 10.8888 - dice_loss: 0.8963flips = False, rotate = False\n",
            "\n",
            "\n",
            "The average loss for epoch 0 is 10.8324.\n",
            "112/112 [==============================] - 8s 39ms/step - loss: 10.8324 - dice_loss: 0.8963 - val_loss: 4.1052 - val_dice_loss: 0.9344 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 4.3434 - dice_loss: 0.8789\n",
            "\n",
            "The average loss for epoch 1 is  4.3382.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 4.3382 - dice_loss: 0.8792 - val_loss: 3.4164 - val_dice_loss: 0.9262 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 3.8226 - dice_loss: 0.8837\n",
            "\n",
            "The average loss for epoch 2 is  3.8201.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 3.8201 - dice_loss: 0.8837 - val_loss: 2.9524 - val_dice_loss: 0.9215 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 3.4909 - dice_loss: 0.8916\n",
            "\n",
            "The average loss for epoch 3 is  3.4911.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 3.4911 - dice_loss: 0.8916 - val_loss: 2.6328 - val_dice_loss: 0.9248 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 3.2807 - dice_loss: 0.9005\n",
            "\n",
            "The average loss for epoch 4 is  3.2786.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 3.2786 - dice_loss: 0.9006 - val_loss: 2.4431 - val_dice_loss: 0.9251 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 3.1352 - dice_loss: 0.9097\n",
            "\n",
            "The average loss for epoch 5 is  3.1367.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 3.1367 - dice_loss: 0.9098 - val_loss: 2.2531 - val_dice_loss: 0.9321 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 3.0444 - dice_loss: 0.9178\n",
            "\n",
            "The average loss for epoch 6 is  3.0428.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 3.0428 - dice_loss: 0.9179 - val_loss: 2.1333 - val_dice_loss: 0.9371 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.9813 - dice_loss: 0.9246\n",
            "\n",
            "The average loss for epoch 7 is  2.9792.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.9792 - dice_loss: 0.9247 - val_loss: 2.0977 - val_dice_loss: 0.9405 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.9310 - dice_loss: 0.9305\n",
            "\n",
            "The average loss for epoch 8 is  2.9322.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.9322 - dice_loss: 0.9305 - val_loss: 2.0521 - val_dice_loss: 0.9442 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8981 - dice_loss: 0.9354\n",
            "\n",
            "The average loss for epoch 9 is  2.8961.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8961 - dice_loss: 0.9355 - val_loss: 1.9662 - val_dice_loss: 0.9486 - lr: 0.0010\n",
            "Epoch 11/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8797 - dice_loss: 0.9395\n",
            "\n",
            "The average loss for epoch 10 is  2.8768.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8768 - dice_loss: 0.9395 - val_loss: 1.9298 - val_dice_loss: 0.9520 - lr: 0.0010\n",
            "Epoch 12/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8587 - dice_loss: 0.9430\n",
            "\n",
            "The average loss for epoch 11 is  2.8601.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 2.8601 - dice_loss: 0.9430 - val_loss: 1.9056 - val_dice_loss: 0.9544 - lr: 0.0010\n",
            "Epoch 13/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8548 - dice_loss: 0.9459\n",
            "\n",
            "The average loss for epoch 12 is  2.8511.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8511 - dice_loss: 0.9459 - val_loss: 1.8938 - val_dice_loss: 0.9566 - lr: 0.0010\n",
            "Epoch 14/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8428 - dice_loss: 0.9482\n",
            "\n",
            "The average loss for epoch 13 is  2.8430.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8430 - dice_loss: 0.9482 - val_loss: 1.8653 - val_dice_loss: 0.9586 - lr: 0.0010\n",
            "Epoch 15/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8390 - dice_loss: 0.9503\n",
            "\n",
            "The average loss for epoch 14 is  2.8380.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8380 - dice_loss: 0.9503 - val_loss: 1.8598 - val_dice_loss: 0.9602 - lr: 0.0010\n",
            "Epoch 16/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8328 - dice_loss: 0.9519\n",
            "\n",
            "The average loss for epoch 15 is  2.8340.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8340 - dice_loss: 0.9519 - val_loss: 1.8271 - val_dice_loss: 0.9616 - lr: 0.0010\n",
            "Epoch 17/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8298 - dice_loss: 0.9533\n",
            "\n",
            "The average loss for epoch 16 is  2.8305.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8305 - dice_loss: 0.9533 - val_loss: 1.8343 - val_dice_loss: 0.9626 - lr: 0.0010\n",
            "Epoch 18/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8310 - dice_loss: 0.9545\n",
            "\n",
            "The average loss for epoch 17 is  2.8301.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8301 - dice_loss: 0.9545 - val_loss: 1.8084 - val_dice_loss: 0.9637 - lr: 0.0010\n",
            "Epoch 19/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8307 - dice_loss: 0.9553\n",
            "\n",
            "The average loss for epoch 18 is  2.8278.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8278 - dice_loss: 0.9553 - val_loss: 1.8105 - val_dice_loss: 0.9642 - lr: 0.0010\n",
            "Epoch 20/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8266 - dice_loss: 0.9561\n",
            "\n",
            "The average loss for epoch 19 is  2.8254.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8254 - dice_loss: 0.9561 - val_loss: 1.8436 - val_dice_loss: 0.9647 - lr: 0.0010\n",
            "Epoch 21/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8260 - dice_loss: 0.9568\n",
            "\n",
            "The average loss for epoch 20 is  2.8239.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8239 - dice_loss: 0.9568 - val_loss: 1.8433 - val_dice_loss: 0.9653 - lr: 0.0010\n",
            "Epoch 22/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8250 - dice_loss: 0.9572\n",
            "\n",
            "The average loss for epoch 21 is  2.8250.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8250 - dice_loss: 0.9572 - val_loss: 1.8282 - val_dice_loss: 0.9656 - lr: 0.0010\n",
            "Epoch 23/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8261 - dice_loss: 0.9576\n",
            "\n",
            "The average loss for epoch 22 is  2.8245.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8245 - dice_loss: 0.9576 - val_loss: 1.8035 - val_dice_loss: 0.9659 - lr: 0.0010\n",
            "Epoch 24/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8245 - dice_loss: 0.9579\n",
            "\n",
            "The average loss for epoch 23 is  2.8217.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8217 - dice_loss: 0.9579 - val_loss: 1.8073 - val_dice_loss: 0.9661 - lr: 0.0010\n",
            "Epoch 25/60\n",
            "112/112 [==============================] - ETA: 0s - loss: 2.8209 - dice_loss: 0.9582\n",
            "\n",
            "The average loss for epoch 24 is  2.8209.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8209 - dice_loss: 0.9582 - val_loss: 1.8174 - val_dice_loss: 0.9662 - lr: 0.0010\n",
            "Epoch 26/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8188 - dice_loss: 0.9585\n",
            "\n",
            "The average loss for epoch 25 is  2.8198.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 2.8198 - dice_loss: 0.9585 - val_loss: 1.8073 - val_dice_loss: 0.9663 - lr: 0.0010\n",
            "Epoch 27/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8255 - dice_loss: 0.9585\n",
            "\n",
            "The average loss for epoch 26 is  2.8220.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8220 - dice_loss: 0.9585 - val_loss: 1.8075 - val_dice_loss: 0.9664 - lr: 0.0010\n",
            "Epoch 28/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8218 - dice_loss: 0.9587\n",
            "\n",
            "The average loss for epoch 27 is  2.8178.\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 2.8178 - dice_loss: 0.9587 - val_loss: 1.8036 - val_dice_loss: 0.9665 - lr: 0.0010\n",
            "Epoch 29/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8207 - dice_loss: 0.9586\n",
            "\n",
            "The average loss for epoch 28 is  2.8220.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8220 - dice_loss: 0.9586 - val_loss: 1.8082 - val_dice_loss: 0.9664 - lr: 5.0000e-04\n",
            "Epoch 30/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8249 - dice_loss: 0.9586\n",
            "\n",
            "The average loss for epoch 29 is  2.8207.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8207 - dice_loss: 0.9586 - val_loss: 1.7926 - val_dice_loss: 0.9664 - lr: 5.0000e-04\n",
            "Epoch 31/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8227 - dice_loss: 0.9587\n",
            "\n",
            "The average loss for epoch 30 is  2.8191.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8191 - dice_loss: 0.9587 - val_loss: 1.8564 - val_dice_loss: 0.9662 - lr: 5.0000e-04\n",
            "Epoch 32/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8159 - dice_loss: 0.9587\n",
            "\n",
            "The average loss for epoch 31 is  2.8182.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8182 - dice_loss: 0.9587 - val_loss: 1.8030 - val_dice_loss: 0.9664 - lr: 5.0000e-04\n",
            "Epoch 33/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8194 - dice_loss: 0.9587\n",
            "\n",
            "The average loss for epoch 32 is  2.8190.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8190 - dice_loss: 0.9587 - val_loss: 1.8288 - val_dice_loss: 0.9663 - lr: 5.0000e-04\n",
            "Epoch 34/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8180 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 33 is  2.8175.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8175 - dice_loss: 0.9588 - val_loss: 1.7914 - val_dice_loss: 0.9665 - lr: 5.0000e-04\n",
            "Epoch 35/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8120 - dice_loss: 0.9587\n",
            "\n",
            "The average loss for epoch 34 is  2.8185.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8185 - dice_loss: 0.9587 - val_loss: 1.8075 - val_dice_loss: 0.9663 - lr: 5.0000e-04\n",
            "Epoch 36/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8193 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 35 is  2.8160.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8160 - dice_loss: 0.9588 - val_loss: 1.8399 - val_dice_loss: 0.9662 - lr: 5.0000e-04\n",
            "Epoch 37/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8126 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 36 is  2.8142.\n",
            "112/112 [==============================] - 4s 33ms/step - loss: 2.8142 - dice_loss: 0.9588 - val_loss: 1.8080 - val_dice_loss: 0.9664 - lr: 5.0000e-04\n",
            "Epoch 38/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8139 - dice_loss: 0.9586\n",
            "\n",
            "The average loss for epoch 37 is  2.8118.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8118 - dice_loss: 0.9586 - val_loss: 1.8295 - val_dice_loss: 0.9662 - lr: 5.0000e-04\n",
            "Epoch 39/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8130 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 38 is  2.8141.\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8141 - dice_loss: 0.9588 - val_loss: 1.8233 - val_dice_loss: 0.9662 - lr: 5.0000e-04\n",
            "Epoch 40/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8164 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 39 is  2.8159.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8159 - dice_loss: 0.9588 - val_loss: 1.7885 - val_dice_loss: 0.9664 - lr: 2.5000e-04\n",
            "Epoch 41/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8144 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 40 is  2.8114.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8114 - dice_loss: 0.9588 - val_loss: 1.8230 - val_dice_loss: 0.9662 - lr: 2.5000e-04\n",
            "Epoch 42/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8165 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 41 is  2.8154.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8154 - dice_loss: 0.9589 - val_loss: 1.8303 - val_dice_loss: 0.9661 - lr: 2.5000e-04\n",
            "Epoch 43/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8159 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 42 is  2.8147.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8147 - dice_loss: 0.9588 - val_loss: 1.8446 - val_dice_loss: 0.9661 - lr: 2.5000e-04\n",
            "Epoch 44/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8133 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 43 is  2.8109.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8109 - dice_loss: 0.9589 - val_loss: 1.7710 - val_dice_loss: 0.9663 - lr: 2.5000e-04\n",
            "Epoch 45/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8147 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 44 is  2.8137.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8137 - dice_loss: 0.9589 - val_loss: 1.8327 - val_dice_loss: 0.9661 - lr: 2.5000e-04\n",
            "Epoch 46/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8127 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 45 is  2.8123.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8123 - dice_loss: 0.9589 - val_loss: 1.8163 - val_dice_loss: 0.9661 - lr: 2.5000e-04\n",
            "Epoch 47/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8115 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 46 is  2.8112.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8112 - dice_loss: 0.9588 - val_loss: 1.8376 - val_dice_loss: 0.9660 - lr: 2.5000e-04\n",
            "Epoch 48/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8152 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 47 is  2.8113.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8113 - dice_loss: 0.9589 - val_loss: 1.8227 - val_dice_loss: 0.9660 - lr: 2.5000e-04\n",
            "Epoch 49/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8085 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 48 is  2.8080.\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8080 - dice_loss: 0.9589 - val_loss: 1.8274 - val_dice_loss: 0.9660 - lr: 2.5000e-04\n",
            "Epoch 50/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8136 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 49 is  2.8094.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8094 - dice_loss: 0.9589 - val_loss: 1.7992 - val_dice_loss: 0.9661 - lr: 1.2500e-04\n",
            "Epoch 51/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8076 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 50 is  2.8083.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8083 - dice_loss: 0.9589 - val_loss: 1.8383 - val_dice_loss: 0.9660 - lr: 1.2500e-04\n",
            "Epoch 52/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8127 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 51 is  2.8118.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8118 - dice_loss: 0.9589 - val_loss: 1.7933 - val_dice_loss: 0.9661 - lr: 1.2500e-04\n",
            "Epoch 53/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8088 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 52 is  2.8065.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8065 - dice_loss: 0.9589 - val_loss: 1.8133 - val_dice_loss: 0.9660 - lr: 1.2500e-04\n",
            "Epoch 54/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8088 - dice_loss: 0.9588\n",
            "\n",
            "The average loss for epoch 53 is  2.8112.\n",
            "\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8112 - dice_loss: 0.9588 - val_loss: 1.7986 - val_dice_loss: 0.9661 - lr: 1.2500e-04\n",
            "Epoch 55/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8079 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 54 is  2.8123.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8123 - dice_loss: 0.9589 - val_loss: 1.8392 - val_dice_loss: 0.9659 - lr: 6.2500e-05\n",
            "Epoch 56/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.8066 - dice_loss: 0.9589\n",
            "\n",
            "The average loss for epoch 55 is  2.8085.\n",
            "Restoring model weights from the end of the best epoch: 44.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.8085 - dice_loss: 0.9589 - val_loss: 1.7852 - val_dice_loss: 0.9661 - lr: 6.2500e-05\n",
            "Epoch 56: early stopping\n",
            "Loading training images and masks.\n",
            "flips = True, rotate = True\n",
            "Epoch 1/60\n",
            "112/112 [==============================] - ETA: 0s - loss: 6.8745 - dice_loss: 0.9036flips = False, rotate = False\n",
            "\n",
            "\n",
            "The average loss for epoch 0 is  6.8745.\n",
            "112/112 [==============================] - 7s 37ms/step - loss: 6.8745 - dice_loss: 0.9036 - val_loss: 2.8630 - val_dice_loss: 0.6250 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.8248 - dice_loss: 0.6801\n",
            "\n",
            "The average loss for epoch 1 is  1.8255.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.8255 - dice_loss: 0.6795 - val_loss: 2.3997 - val_dice_loss: 0.5836 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6580 - dice_loss: 0.6555\n",
            "\n",
            "The average loss for epoch 2 is  1.6574.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.6574 - dice_loss: 0.6553 - val_loss: 2.2371 - val_dice_loss: 0.5790 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.5755 - dice_loss: 0.6426\n",
            "\n",
            "The average loss for epoch 3 is  1.5741.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.5741 - dice_loss: 0.6423 - val_loss: 2.2625 - val_dice_loss: 0.5779 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.5276 - dice_loss: 0.6361\n",
            "\n",
            "The average loss for epoch 4 is  1.5252.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.5252 - dice_loss: 0.6365 - val_loss: 2.0942 - val_dice_loss: 0.5556 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "112/112 [==============================] - ETA: 0s - loss: 1.4850 - dice_loss: 0.6312\n",
            "\n",
            "The average loss for epoch 5 is  1.4850.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.4850 - dice_loss: 0.6312 - val_loss: 2.1345 - val_dice_loss: 0.5658 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4579 - dice_loss: 0.6244\n",
            "\n",
            "The average loss for epoch 6 is  1.4559.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.4559 - dice_loss: 0.6250 - val_loss: 2.0530 - val_dice_loss: 0.5750 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4321 - dice_loss: 0.6214\n",
            "\n",
            "The average loss for epoch 7 is  1.4324.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.4324 - dice_loss: 0.6216 - val_loss: 2.1198 - val_dice_loss: 0.5850 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4169 - dice_loss: 0.6191\n",
            "\n",
            "The average loss for epoch 8 is  1.4158.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.4158 - dice_loss: 0.6189 - val_loss: 2.0997 - val_dice_loss: 0.5697 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.4010 - dice_loss: 0.6168\n",
            "\n",
            "The average loss for epoch 9 is  1.4015.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.4015 - dice_loss: 0.6168 - val_loss: 1.9458 - val_dice_loss: 0.5549 - lr: 0.0010\n",
            "Epoch 11/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3911 - dice_loss: 0.6148\n",
            "\n",
            "The average loss for epoch 10 is  1.3908.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3908 - dice_loss: 0.6146 - val_loss: 1.9258 - val_dice_loss: 0.5433 - lr: 0.0010\n",
            "Epoch 12/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3782 - dice_loss: 0.6113\n",
            "\n",
            "The average loss for epoch 11 is  1.3778.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3778 - dice_loss: 0.6109 - val_loss: 2.0123 - val_dice_loss: 0.5631 - lr: 0.0010\n",
            "Epoch 13/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3673 - dice_loss: 0.6088\n",
            "\n",
            "The average loss for epoch 12 is  1.3698.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3698 - dice_loss: 0.6085 - val_loss: 1.9990 - val_dice_loss: 0.5730 - lr: 0.0010\n",
            "Epoch 14/60\n",
            "112/112 [==============================] - ETA: 0s - loss: 1.3611 - dice_loss: 0.6059\n",
            "\n",
            "The average loss for epoch 13 is  1.3611.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3611 - dice_loss: 0.6059 - val_loss: 1.9709 - val_dice_loss: 0.5665 - lr: 0.0010\n",
            "Epoch 15/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3532 - dice_loss: 0.6056\n",
            "\n",
            "The average loss for epoch 14 is  1.3531.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3531 - dice_loss: 0.6055 - val_loss: 2.0405 - val_dice_loss: 0.5788 - lr: 0.0010\n",
            "Epoch 16/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3465 - dice_loss: 0.6003\n",
            "\n",
            "The average loss for epoch 15 is  1.3454.\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3454 - dice_loss: 0.6008 - val_loss: 2.0464 - val_dice_loss: 0.5856 - lr: 0.0010\n",
            "Epoch 17/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3397 - dice_loss: 0.5988\n",
            "\n",
            "The average loss for epoch 16 is  1.3389.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3389 - dice_loss: 0.5991 - val_loss: 1.9715 - val_dice_loss: 0.5664 - lr: 5.0000e-04\n",
            "Epoch 18/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3336 - dice_loss: 0.5981\n",
            "\n",
            "The average loss for epoch 17 is  1.3353.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3353 - dice_loss: 0.5982 - val_loss: 1.9798 - val_dice_loss: 0.5739 - lr: 5.0000e-04\n",
            "Epoch 19/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3309 - dice_loss: 0.5985\n",
            "\n",
            "The average loss for epoch 18 is  1.3311.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3311 - dice_loss: 0.5983 - val_loss: 1.9585 - val_dice_loss: 0.5579 - lr: 5.0000e-04\n",
            "Epoch 20/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3280 - dice_loss: 0.5968\n",
            "\n",
            "The average loss for epoch 19 is  1.3276.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.3276 - dice_loss: 0.5966 - val_loss: 2.0071 - val_dice_loss: 0.5648 - lr: 5.0000e-04\n",
            "Epoch 21/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3211 - dice_loss: 0.5940\n",
            "\n",
            "The average loss for epoch 20 is  1.3247.\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3247 - dice_loss: 0.5939 - val_loss: 2.0053 - val_dice_loss: 0.5690 - lr: 5.0000e-04\n",
            "Epoch 22/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3198 - dice_loss: 0.5912\n",
            "\n",
            "The average loss for epoch 21 is  1.3197.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3197 - dice_loss: 0.5915 - val_loss: 1.9501 - val_dice_loss: 0.5584 - lr: 2.5000e-04\n",
            "Epoch 23/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.3176 - dice_loss: 0.5909\n",
            "\n",
            "The average loss for epoch 22 is  1.3173.\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.3173 - dice_loss: 0.5909 - val_loss: 1.9902 - val_dice_loss: 0.5673 - lr: 2.5000e-04\n",
            "Epoch 23: early stopping\n",
            "Loading training images and masks.\n",
            "flips = True, rotate = True\n",
            "Epoch 1/60\n",
            "112/112 [==============================] - ETA: 0s - loss: 6.5977 - dice_loss: 0.8582flips = False, rotate = False\n",
            "\n",
            "\n",
            "The average loss for epoch 0 is  6.5977.\n",
            "112/112 [==============================] - 7s 35ms/step - loss: 6.5977 - dice_loss: 0.8582 - val_loss: 1.1871 - val_dice_loss: 0.7378 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 2.0904 - dice_loss: 0.6221\n",
            "\n",
            "The average loss for epoch 1 is  2.0936.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 2.0936 - dice_loss: 0.6218 - val_loss: 1.0852 - val_dice_loss: 0.7001 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.9022 - dice_loss: 0.5963\n",
            "\n",
            "The average loss for epoch 2 is  1.9018.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.9018 - dice_loss: 0.5961 - val_loss: 1.0435 - val_dice_loss: 0.7005 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.8280 - dice_loss: 0.5873\n",
            "\n",
            "The average loss for epoch 3 is  1.8262.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.8262 - dice_loss: 0.5874 - val_loss: 1.0353 - val_dice_loss: 0.6965 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.7720 - dice_loss: 0.5764\n",
            "\n",
            "The average loss for epoch 4 is  1.7715.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.7715 - dice_loss: 0.5766 - val_loss: 1.0495 - val_dice_loss: 0.6973 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.7425 - dice_loss: 0.5705\n",
            "\n",
            "The average loss for epoch 5 is  1.7416.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.7416 - dice_loss: 0.5705 - val_loss: 1.0215 - val_dice_loss: 0.7015 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.7208 - dice_loss: 0.5671\n",
            "\n",
            "The average loss for epoch 6 is  1.7196.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.7196 - dice_loss: 0.5671 - val_loss: 1.0443 - val_dice_loss: 0.6922 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6969 - dice_loss: 0.5630\n",
            "\n",
            "The average loss for epoch 7 is  1.6981.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6981 - dice_loss: 0.5630 - val_loss: 1.0445 - val_dice_loss: 0.6866 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6850 - dice_loss: 0.5608\n",
            "\n",
            "The average loss for epoch 8 is  1.6842.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6842 - dice_loss: 0.5608 - val_loss: 1.0225 - val_dice_loss: 0.7115 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6684 - dice_loss: 0.5578\n",
            "\n",
            "The average loss for epoch 9 is  1.6690.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6690 - dice_loss: 0.5577 - val_loss: 1.0245 - val_dice_loss: 0.7063 - lr: 0.0010\n",
            "Epoch 11/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6629 - dice_loss: 0.5575\n",
            "\n",
            "The average loss for epoch 10 is  1.6630.\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.6630 - dice_loss: 0.5576 - val_loss: 1.0469 - val_dice_loss: 0.7150 - lr: 0.0010\n",
            "Epoch 12/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6532 - dice_loss: 0.5537\n",
            "\n",
            "The average loss for epoch 11 is  1.6520.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6520 - dice_loss: 0.5540 - val_loss: 1.0324 - val_dice_loss: 0.7007 - lr: 5.0000e-04\n",
            "Epoch 13/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6472 - dice_loss: 0.5531\n",
            "\n",
            "The average loss for epoch 12 is  1.6479.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6479 - dice_loss: 0.5529 - val_loss: 1.0465 - val_dice_loss: 0.7007 - lr: 5.0000e-04\n",
            "Epoch 14/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6415 - dice_loss: 0.5517\n",
            "\n",
            "The average loss for epoch 13 is  1.6416.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6416 - dice_loss: 0.5514 - val_loss: 1.0532 - val_dice_loss: 0.7142 - lr: 5.0000e-04\n",
            "Epoch 15/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6377 - dice_loss: 0.5515\n",
            "\n",
            "The average loss for epoch 14 is  1.6376.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6376 - dice_loss: 0.5515 - val_loss: 1.0827 - val_dice_loss: 0.7141 - lr: 5.0000e-04\n",
            "Epoch 16/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6352 - dice_loss: 0.5511\n",
            "\n",
            "The average loss for epoch 15 is  1.6344.\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.6344 - dice_loss: 0.5512 - val_loss: 1.0282 - val_dice_loss: 0.7108 - lr: 5.0000e-04\n",
            "Epoch 17/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6257 - dice_loss: 0.5480\n",
            "\n",
            "The average loss for epoch 16 is  1.6263.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.6263 - dice_loss: 0.5482 - val_loss: 1.0894 - val_dice_loss: 0.7264 - lr: 2.5000e-04\n",
            "Epoch 18/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6231 - dice_loss: 0.5481\n",
            "\n",
            "The average loss for epoch 17 is  1.6251.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6251 - dice_loss: 0.5482 - val_loss: 1.0122 - val_dice_loss: 0.7099 - lr: 2.5000e-04\n",
            "Epoch 19/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6262 - dice_loss: 0.5471\n",
            "\n",
            "The average loss for epoch 18 is  1.6245.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6245 - dice_loss: 0.5471 - val_loss: 1.0276 - val_dice_loss: 0.7040 - lr: 2.5000e-04\n",
            "Epoch 20/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6206 - dice_loss: 0.5462\n",
            "\n",
            "The average loss for epoch 19 is  1.6196.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6196 - dice_loss: 0.5462 - val_loss: 1.1025 - val_dice_loss: 0.7068 - lr: 2.5000e-04\n",
            "Epoch 21/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6178 - dice_loss: 0.5460\n",
            "\n",
            "The average loss for epoch 20 is  1.6175.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6175 - dice_loss: 0.5461 - val_loss: 1.0485 - val_dice_loss: 0.7292 - lr: 2.5000e-04\n",
            "Epoch 22/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6123 - dice_loss: 0.5468\n",
            "\n",
            "The average loss for epoch 21 is  1.6152.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6152 - dice_loss: 0.5466 - val_loss: 1.0791 - val_dice_loss: 0.7102 - lr: 2.5000e-04\n",
            "Epoch 23/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6131 - dice_loss: 0.5446\n",
            "\n",
            "The average loss for epoch 22 is  1.6119.\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6119 - dice_loss: 0.5446 - val_loss: 1.0546 - val_dice_loss: 0.7207 - lr: 2.5000e-04\n",
            "Epoch 24/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6095 - dice_loss: 0.5432\n",
            "\n",
            "The average loss for epoch 23 is  1.6100.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6100 - dice_loss: 0.5432 - val_loss: 1.0425 - val_dice_loss: 0.7243 - lr: 1.2500e-04\n",
            "Epoch 25/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6110 - dice_loss: 0.5445\n",
            "\n",
            "The average loss for epoch 24 is  1.6095.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6095 - dice_loss: 0.5445 - val_loss: 1.0627 - val_dice_loss: 0.7131 - lr: 1.2500e-04\n",
            "Epoch 26/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6059 - dice_loss: 0.5435\n",
            "\n",
            "The average loss for epoch 25 is  1.6065.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6065 - dice_loss: 0.5436 - val_loss: 1.0890 - val_dice_loss: 0.7274 - lr: 1.2500e-04\n",
            "Epoch 27/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6042 - dice_loss: 0.5436\n",
            "\n",
            "The average loss for epoch 26 is  1.6048.\n",
            "112/112 [==============================] - 4s 35ms/step - loss: 1.6048 - dice_loss: 0.5433 - val_loss: 1.0878 - val_dice_loss: 0.7219 - lr: 1.2500e-04\n",
            "Epoch 28/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6034 - dice_loss: 0.5426\n",
            "\n",
            "The average loss for epoch 27 is  1.6051.\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6051 - dice_loss: 0.5423 - val_loss: 1.0490 - val_dice_loss: 0.7257 - lr: 1.2500e-04\n",
            "Epoch 29/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6021 - dice_loss: 0.5415\n",
            "\n",
            "The average loss for epoch 28 is  1.6017.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6017 - dice_loss: 0.5415 - val_loss: 1.1178 - val_dice_loss: 0.7117 - lr: 6.2500e-05\n",
            "Epoch 30/60\n",
            "111/112 [============================>.] - ETA: 0s - loss: 1.6068 - dice_loss: 0.5435\n",
            "\n",
            "The average loss for epoch 29 is  1.6061.\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "112/112 [==============================] - 4s 34ms/step - loss: 1.6061 - dice_loss: 0.5436 - val_loss: 1.0584 - val_dice_loss: 0.7214 - lr: 6.2500e-05\n",
            "Epoch 30: early stopping\n",
            "Video mouse3\n",
            "Load data: 1.51279616355896 s\n",
            "16/16 [==============================] - 2s 70ms/step\n",
            "Average infrence time 2.6206007571803367 ms/frame\n",
            "Using thresh_pmap=110\n",
            "Used 2.0384209156036377 s\n",
            "Using thresh_pmap=120\n",
            "Used 4.027503490447998 s\n",
            "Using thresh_pmap=130\n",
            "Used 6.018548011779785 s\n",
            "Using thresh_pmap=140\n",
            "Used 8.00386357307434 s\n",
            "Using thresh_pmap=150\n",
            "Used 10.008572101593018 s\n",
            "Using thresh_pmap=160\n",
            "Used 11.992407321929932 s\n",
            "Using thresh_pmap=170\n",
            "Used 13.969521760940552 s\n",
            "Using thresh_pmap=180\n",
            "Used 15.957588911056519 s\n",
            "Using thresh_pmap=190\n",
            "Used 17.972017526626587 s\n",
            "Using thresh_pmap=200\n",
            "Used 19.987324714660645 s\n",
            "Using thresh_pmap=210\n",
            "Used 21.961745262145996 s\n",
            "Using thresh_pmap=220\n",
            "Used 23.969446659088135 s\n",
            "Using thresh_pmap=230\n",
            "Used 25.931752920150757 s\n",
            "16/16 [==============================] - 1s 37ms/step\n",
            "Average infrence time 1.577778968691452 ms/frame\n",
            "Using thresh_pmap=110\n",
            "Used 4.935686349868774 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 52.41840863227844 s, Best F1 is 0.08623548922056384\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 99.70862412452698 s, Best F1 is 0.08803986710963455\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 146.74731159210205 s, Best F1 is 0.08803986710963455\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 193.25277137756348 s, Best F1 is 0.08668242710795902\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 238.16307282447815 s, Best F1 is 0.09379968203497616\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 282.86785101890564 s, Best F1 is 0.0929839391377853\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 326.33133029937744 s, Best F1 is 0.09539207760711398\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 369.754487991333 s, Best F1 is 0.09539207760711398\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 412.9449872970581 s, Best F1 is 0.09564474807856532\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 454.8075349330902 s, Best F1 is 0.08927038626609442\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 496.26381158828735 s, Best F1 is 0.09098712446351932\n",
            "Using thresh_pmap=120\n",
            "Used 500.9108808040619 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 543.6790850162506 s, Best F1 is 0.08633093525179857\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 585.4573962688446 s, Best F1 is 0.08724832214765099\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 627.8532843589783 s, Best F1 is 0.08724832214765099\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 668.7416703701019 s, Best F1 is 0.09098567818028643\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 709.2574622631073 s, Best F1 is 0.09282700421940927\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 748.8156614303589 s, Best F1 is 0.0937766410912191\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 787.4970688819885 s, Best F1 is 0.09580838323353294\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 826.7245719432831 s, Best F1 is 0.09580838323353294\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 864.7278578281403 s, Best F1 is 0.09827586206896552\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 902.254234790802 s, Best F1 is 0.09836065573770493\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 939.5167376995087 s, Best F1 is 0.09904430929626411\n",
            "Using thresh_pmap=130\n",
            "Used 943.983969449997 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 980.5720980167389 s, Best F1 is 0.08628127696289906\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1015.6239085197449 s, Best F1 is 0.08311688311688312\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1050.9485847949982 s, Best F1 is 0.08311688311688312\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1085.1349291801453 s, Best F1 is 0.0818815331010453\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1118.4967603683472 s, Best F1 is 0.08145580589254765\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1151.805496931076 s, Best F1 is 0.08027923211169284\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1184.3267300128937 s, Best F1 is 0.08274647887323944\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1217.3462727069855 s, Best F1 is 0.08274647887323944\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1249.1192507743835 s, Best F1 is 0.08239095315024232\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1279.8581500053406 s, Best F1 is 0.08441558441558442\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1311.4333293437958 s, Best F1 is 0.0849673202614379\n",
            "Using thresh_pmap=140\n",
            "Used 1315.3391902446747 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1344.497635602951 s, Best F1 is 0.0647985989492119\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1373.6510183811188 s, Best F1 is 0.06445497630331753\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1401.630652666092 s, Best F1 is 0.06445497630331753\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1429.4651594161987 s, Best F1 is 0.06863679694947568\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1456.4163398742676 s, Best F1 is 0.07115384615384615\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1483.4004180431366 s, Best F1 is 0.07142857142857142\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1509.5489692687988 s, Best F1 is 0.07215541165587419\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1541.6413252353668 s, Best F1 is 0.07215541165587419\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1580.2353801727295 s, Best F1 is 0.07228915662650602\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1617.2678575515747 s, Best F1 is 0.07706093189964158\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=140\n",
            "Used 1642.9438552856445 s, Best F1 is 0.0775473399458972\n",
            "Using thresh_pmap=150\n",
            "Used 1647.3385860919952 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1672.9353489875793 s, Best F1 is 0.04623115577889447\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1697.7583649158478 s, Best F1 is 0.0486854917234664\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1722.819212436676 s, Best F1 is 0.0486854917234664\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1743.4301598072052 s, Best F1 is 0.05479452054794521\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1759.7232630252838 s, Best F1 is 0.055226824457593686\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1778.9412710666656 s, Best F1 is 0.05736894164193867\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1802.1833229064941 s, Best F1 is 0.057654075546719676\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1824.5357563495636 s, Best F1 is 0.057654075546719676\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1847.2888865470886 s, Best F1 is 0.05753968253968254\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1865.2670686244965 s, Best F1 is 0.05988023952095809\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=150\n",
            "Used 1880.0467574596405 s, Best F1 is 0.061876247504990024\n",
            "Using thresh_pmap=160\n",
            "Used 1882.840966463089 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1890.3754415512085 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1898.0122046470642 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1906.107299566269 s, Best F1 is 0.0\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1912.8354477882385 s, Best F1 is 0.0\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1918.4694802761078 s, Best F1 is 0.002628120893561104\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1923.165863275528 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1927.0656533241272 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1930.962281703949 s, Best F1 is 0.0\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1934.3720026016235 s, Best F1 is 0.0\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1937.4206352233887 s, Best F1 is 0.0\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=160\n",
            "Used 1940.1482677459717 s, Best F1 is 0.0\n",
            "Using thresh_pmap=170\n",
            "Used 1943.629450082779 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1948.6371448040009 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1952.7772703170776 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1956.8927721977234 s, Best F1 is 0.0\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1960.301334619522 s, Best F1 is 0.0\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1963.1223697662354 s, Best F1 is 0.0\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1965.452612400055 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1967.3213028907776 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1969.1799614429474 s, Best F1 is 0.0\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1970.8192672729492 s, Best F1 is 0.0\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1972.2361285686493 s, Best F1 is 0.0\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=170\n",
            "Used 1973.4060955047607 s, Best F1 is 0.0\n",
            "Using thresh_pmap=180\n",
            "Used 1976.6372983455658 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1978.8869721889496 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1980.5493376255035 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1982.2480013370514 s, Best F1 is 0.0\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1983.531477689743 s, Best F1 is 0.0\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1984.5375525951385 s, Best F1 is 0.0\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1985.3882734775543 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1986.0913407802582 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1986.7904908657074 s, Best F1 is 0.0\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1987.3999392986298 s, Best F1 is 0.0\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1987.9718482494354 s, Best F1 is 0.0\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=180\n",
            "Used 1988.408302307129 s, Best F1 is 0.0\n",
            "Using thresh_pmap=190\n",
            "Used 1990.538803100586 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1992.9299330711365 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1994.09774184227 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1995.1845786571503 s, Best F1 is 0.0\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1995.9914155006409 s, Best F1 is 0.0\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1996.6044101715088 s, Best F1 is 0.0\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1997.0636928081512 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1997.444853067398 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1997.8085956573486 s, Best F1 is 0.0\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1998.1415903568268 s, Best F1 is 0.0\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1998.4625675678253 s, Best F1 is 0.0\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=190\n",
            "Used 1998.7575209140778 s, Best F1 is 0.0\n",
            "Using thresh_pmap=200\n",
            "Used 2000.9035687446594 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2001.9446244239807 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2002.6687898635864 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2003.416211605072 s, Best F1 is 0.0\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2003.9354207515717 s, Best F1 is 0.0\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2004.4511814117432 s, Best F1 is 0.0\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2004.9980947971344 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2005.4266214370728 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2005.8135261535645 s, Best F1 is 0.0\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2006.080600976944 s, Best F1 is 0.0\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2006.2722642421722 s, Best F1 is 0.0\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=200\n",
            "Used 2006.453753232956 s, Best F1 is 0.0\n",
            "Using thresh_pmap=210\n",
            "Used 2008.6768321990967 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2009.285044670105 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2009.7547273635864 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2010.2092306613922 s, Best F1 is 0.0\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2010.5623347759247 s, Best F1 is 0.0\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2010.846184015274 s, Best F1 is 0.0\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2011.0642585754395 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2011.2887120246887 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2011.4887325763702 s, Best F1 is 0.0\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2011.689283132553 s, Best F1 is 0.0\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2011.8416819572449 s, Best F1 is 0.0\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=210\n",
            "Used 2011.9936435222626 s, Best F1 is 0.0\n",
            "Using thresh_pmap=220\n",
            "Used 2014.983387708664 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2015.439911365509 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2015.7265248298645 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.0114624500275 s, Best F1 is 0.0\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.2497923374176 s, Best F1 is 0.0\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.394805431366 s, Best F1 is 0.0\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.395295381546 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.3955347537994 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.395753622055 s, Best F1 is 0.0\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.3959860801697 s, Best F1 is 0.0\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.3962001800537 s, Best F1 is 0.0\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=220\n",
            "Used 2016.3964095115662 s, Best F1 is 0.0\n",
            "Using thresh_pmap=230\n",
            "Used 2019.2976343631744 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.6287968158722 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.7903263568878 s, Best F1 is 0.0\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.953320980072 s, Best F1 is 0.0\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.9537138938904 s, Best F1 is 0.0\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.953957080841 s, Best F1 is 0.0\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.9541959762573 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.9544112682343 s, Best F1 is 0.0\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.9546251296997 s, Best F1 is 0.0\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.9548335075378 s, Best F1 is 0.0\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.9550528526306 s, Best F1 is 0.0\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=230\n",
            "Used 2019.9552614688873 s, Best F1 is 0.0\n",
            "16/16 [==============================] - 1s 46ms/step\n",
            "Average infrence time 2.8515951760510294 ms/frame\n",
            "Using thresh_pmap=110\n",
            "Used 6.71031928062439 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 56.91034460067749 s, Best F1 is 0.07985803016858917\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 94.33484768867493 s, Best F1 is 0.0855614973262032\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 140.54278707504272 s, Best F1 is 0.0855614973262032\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 189.25720977783203 s, Best F1 is 0.08407871198568873\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 223.96255826950073 s, Best F1 is 0.08820882088208822\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 270.52495861053467 s, Best F1 is 0.08976660682226212\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 315.2781500816345 s, Best F1 is 0.08942390369733447\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 349.26464438438416 s, Best F1 is 0.08942390369733447\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 394.4611883163452 s, Best F1 is 0.08767576509511994\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 436.7083840370178 s, Best F1 is 0.08398950131233596\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=110\n",
            "Used 469.30001997947693 s, Best F1 is 0.08947368421052632\n",
            "Using thresh_pmap=120\n",
            "Used 475.6696455478668 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 520.7452385425568 s, Best F1 is 0.07433016421780468\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 558.4074234962463 s, Best F1 is 0.07761732851985559\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 587.6634163856506 s, Best F1 is 0.07761732851985559\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 615.6258325576782 s, Best F1 is 0.0823327615780446\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 645.2687301635742 s, Best F1 is 0.08838821490467938\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 685.172444820404 s, Best F1 is 0.09019947961838683\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 726.694741487503 s, Best F1 is 0.09035621198957428\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 758.80388879776 s, Best F1 is 0.09035621198957428\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 797.7610356807709 s, Best F1 is 0.09099350046425254\n",
            "Using minArea=12.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 837.7416379451752 s, Best F1 is 0.08768656716417911\n",
            "Using minArea=13.0, avgArea=28.0, thresh_pmap=120\n",
            "Used 869.1291031837463 s, Best F1 is 0.08518189884649512\n",
            "Using thresh_pmap=130\n",
            "Used 873.597002029419 s\n",
            "Using minArea=5.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 908.5074844360352 s, Best F1 is 0.07421150278293136\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 948.4255993366241 s, Best F1 is 0.07269338303821063\n",
            "Using minArea=6.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 982.2696795463562 s, Best F1 is 0.07269338303821063\n",
            "Using minArea=7.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1007.173689365387 s, Best F1 is 0.07392996108949415\n",
            "Using minArea=8.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1031.8913843631744 s, Best F1 is 0.07378640776699029\n",
            "Using minArea=9.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1056.722558259964 s, Best F1 is 0.07774538386783285\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1080.6161692142487 s, Best F1 is 0.07511737089201877\n",
            "Using minArea=10.0, avgArea=28.0, thresh_pmap=130\n",
            "Used 1104.3222250938416 s, Best F1 is 0.07511737089201877\n",
            "Using minArea=11.0, avgArea=28.0, thresh_pmap=130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-14:\n",
            "Process ForkPoolWorker-1:\n",
            "Process ForkPoolWorker-18:\n",
            "Process ForkPoolWorker-11:\n",
            "Process ForkPoolWorker-15:\n",
            "Process ForkPoolWorker-3:\n",
            "Process ForkPoolWorker-17:\n",
            "Process ForkPoolWorker-8:\n",
            "Process ForkPoolWorker-6:\n",
            "Process ForkPoolWorker-10:\n",
            "Process ForkPoolWorker-12:\n",
            "Process ForkPoolWorker-19:\n",
            "Process ForkPoolWorker-9:\n",
            "Process ForkPoolWorker-29:\n",
            "Process ForkPoolWorker-5:\n",
            "Process ForkPoolWorker-16:\n",
            "Process ForkPoolWorker-2:\n",
            "Process ForkPoolWorker-25:\n",
            "Process ForkPoolWorker-7:\n",
            "Process ForkPoolWorker-23:\n",
            "Process ForkPoolWorker-20:\n",
            "Process ForkPoolWorker-24:\n",
            "Process ForkPoolWorker-28:\n",
            "Process ForkPoolWorker-38:\n",
            "Process ForkPoolWorker-35:\n",
            "Process ForkPoolWorker-34:\n",
            "Process ForkPoolWorker-4:\n",
            "Process ForkPoolWorker-21:\n",
            "Process ForkPoolWorker-26:\n",
            "Process ForkPoolWorker-22:\n",
            "Process ForkPoolWorker-13:\n",
            "Process ForkPoolWorker-30:\n",
            "Process ForkPoolWorker-31:\n",
            "Process ForkPoolWorker-37:\n",
            "Process ForkPoolWorker-33:\n",
            "Process ForkPoolWorker-39:\n",
            "Process ForkPoolWorker-36:\n",
            "Process ForkPoolWorker-27:\n",
            "Process ForkPoolWorker-40:\n",
            "Process ForkPoolWorker-32:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
            "    with self._rlock:\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/gpfs/home/bizzin01/.conda/envs/tensorflow-2.12/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "Process ForkPoolWorker-41:\n",
            "Process ForkPoolWorker-63:\n",
            "Process ForkPoolWorker-46:\n",
            "Process ForkPoolWorker-64:\n",
            "Process ForkPoolWorker-50:\n",
            "Process ForkPoolWorker-47:\n",
            "Process ForkPoolWorker-70:\n",
            "Process ForkPoolWorker-42:\n",
            "Process ForkPoolWorker-43:\n",
            "Process ForkPoolWorker-48:\n",
            "Process ForkPoolWorker-51:\n",
            "Process ForkPoolWorker-65:\n",
            "Process ForkPoolWorker-44:\n",
            "Process ForkPoolWorker-62:\n",
            "Process ForkPoolWorker-45:\n",
            "Process ForkPoolWorker-75:\n",
            "Process ForkPoolWorker-76:\n",
            "Process ForkPoolWorker-72:\n",
            "Process ForkPoolWorker-69:\n",
            "Process ForkPoolWorker-68:\n",
            "Process ForkPoolWorker-77:\n",
            "Process ForkPoolWorker-49:\n",
            "Process ForkPoolWorker-66:\n",
            "Process ForkPoolWorker-78:\n",
            "Process ForkPoolWorker-74:\n",
            "Process ForkPoolWorker-67:\n",
            "Process ForkPoolWorker-79:\n",
            "Process ForkPoolWorker-71:\n",
            "Process ForkPoolWorker-52:\n",
            "Process ForkPoolWorker-73:\n",
            "Process ForkPoolWorker-58:\n",
            "Process ForkPoolWorker-59:\n",
            "Process ForkPoolWorker-53:\n",
            "Process ForkPoolWorker-57:\n",
            "Process ForkPoolWorker-55:\n",
            "Process ForkPoolWorker-56:\n",
            "Process ForkPoolWorker-60:\n",
            "Process ForkPoolWorker-61:\n",
            "Process ForkPoolWorker-54:\n",
            "Process ForkPoolWorker-80:\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os, sys, runpy, traceback\n",
        "\n",
        "REPO_ROOT = \"/gpfs/home/bizzin01/nicole/code/SUNS_nicole\"\n",
        "os.chdir(REPO_ROOT)\n",
        "SCRIPT = f\"{REPO_ROOT}/demo/train_3_test_1/demo_train_CNN_params.py\"\n",
        "print(\"CWD:\", os.getcwd())\n",
        "print(\"Running:\", SCRIPT)\n",
        "\n",
        "try:\n",
        "    res = runpy.run_path(SCRIPT, run_name=\"__main__\")\n",
        "    print(\"Finished run.\")\n",
        "except SystemExit as e:\n",
        "    print(\"SystemExit:\", e.code)\n",
        "except Exception:\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train SUNS (train_3_test_1)\n",
        "\n",
        "This notebook runs the demo training script and saves outputs to `output_4mouse` under the `line3_dataset` dataset, as configured in `suns/config.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACTIVE_EXP_SET = mouse7_new\n",
            "DATAFOLDER    = /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new\n",
            "OUTPUT_FOLDER = output_IOU_02\n",
            "EXP_IDs       = ['mouse7_773', 'mouse7_774', 'mouse7_775', 'mouse7_776']\n"
          ]
        }
      ],
      "source": [
        "# --- Setup & configuration ---\n",
        "import os, sys, runpy, pprint\n",
        "\n",
        "REPO_ROOT = '/gpfs/home/bizzin01/nicole/code/SUNS_nicole'\n",
        "if REPO_ROOT not in sys.path:\n",
        "    sys.path.insert(0, REPO_ROOT)\n",
        "\n",
        "from suns import config as suns_config\n",
        "\n",
        "ACTIVE = suns_config.ACTIVE_EXP_SET\n",
        "print('ACTIVE_EXP_SET =', ACTIVE)\n",
        "print('DATAFOLDER    =', suns_config.DATAFOLDER_SETS[ACTIVE])\n",
        "print('OUTPUT_FOLDER =', suns_config.OUTPUT_FOLDER[ACTIVE])\n",
        "print('EXP_IDs       =', suns_config.EXP_ID_SETS[ACTIVE])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIR_PARENT : /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/output_IOU_02\n",
            "DIR_OUTPUT : /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/output_IOU_02/output_masks\n"
          ]
        }
      ],
      "source": [
        "# --- Resolve paths ---\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "ACTIVE = suns_config.ACTIVE_EXP_SET\n",
        "DIR_VIDEO = suns_config.DATAFOLDER_SETS[ACTIVE]\n",
        "DIR_PARENT = os.path.join(DIR_VIDEO, suns_config.OUTPUT_FOLDER[ACTIVE])\n",
        "DIR_NET_IN = os.path.join(DIR_PARENT, 'network_input')\n",
        "DIR_WEIGHTS = os.path.join(DIR_PARENT, 'Weights')\n",
        "DIR_TRAINOUT = os.path.join(DIR_PARENT, 'training output')\n",
        "DIR_OUTPUT = os.path.join(DIR_PARENT, 'output_masks')\n",
        "DIR_TEMP = os.path.join(DIR_PARENT, 'temp')\n",
        "\n",
        "for d in [DIR_NET_IN, DIR_WEIGHTS, DIR_TRAINOUT, DIR_OUTPUT, DIR_TEMP]:\n",
        "    Path(d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('DIR_PARENT :', DIR_PARENT)\n",
        "print('DIR_OUTPUT :', DIR_OUTPUT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running: /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/train_3_test_1/demo_train_CNN_params.py\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'runpy' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m SCRIPT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mREPO_ROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/demo/train_3_test_1/demo_train_CNN_params.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m'\u001b[39m, SCRIPT)\n\u001b[0;32m----> 5\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrunpy\u001b[49m\u001b[38;5;241m.\u001b[39mrun_path(SCRIPT, run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished run.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'runpy' is not defined"
          ]
        }
      ],
      "source": [
        "# --- Run the training & parameter optimization script ---\n",
        "# This executes demo/train_3_test_1/demo_train_CNN_params.py as __main__\n",
        "SCRIPT = f\"{REPO_ROOT}/demo/train_3_test_1/demo_train_CNN_params.py\"\n",
        "print('Running:', SCRIPT)\n",
        "res = runpy.run_path(SCRIPT, run_name='__main__')\n",
        "print('Finished run.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import subprocess, os\n",
        "# for id in mouse7_773 mouse7_774 mouse7_775 mouse7_776; do\n",
        "#   python /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/export_output_masks_IOU_02.py --exp_id \"$id\" --cv 0\n",
        "# done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "importing config\n",
            "Export script: /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/export_output_masks_IOU_02.py\n",
            "Exporting masks for mouse7_773 (cv=0)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-31 11:42:23.031273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing mouse7_773 with:\n",
            "  model: /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/output_IOU_02/Weights/Model_CV0.h5\n",
            "  opt:   /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/output_IOU_02/output_masks/Optimization_Info_0.mat\n",
            "  out:   /gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/output_IOU_02/output_masks\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-31 11:42:54.070752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14784 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
            "2025-10-31 11:42:56.072323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8907\n",
            "2025-10-31 11:42:56.888631: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - dice_loss: 0.0102\n",
            "Initialization time: 4.709472894668579 s\n",
            "256 256 1600 -> 256 256 1600\n",
            "FFT planning: 0.23353028297424316 s\n",
            "Initialization: 0.10536003112792969 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-3:\n",
            "Process ForkPoolWorker-4:\n",
            "Process ForkPoolWorker-32:\n",
            "Process ForkPoolWorker-22:\n",
            "Process ForkPoolWorker-18:\n",
            "Process ForkPoolWorker-31:\n",
            "Process ForkPoolWorker-17:\n",
            "Process ForkPoolWorker-15:\n",
            "Process ForkPoolWorker-1:\n",
            "Process ForkPoolWorker-30:\n",
            "Process ForkPoolWorker-8:\n",
            "Process ForkPoolWorker-23:\n",
            "Process ForkPoolWorker-35:\n",
            "Process ForkPoolWorker-34:\n",
            "Process ForkPoolWorker-38:\n",
            "Process ForkPoolWorker-24:\n",
            "Process ForkPoolWorker-11:\n",
            "Process ForkPoolWorker-27:\n",
            "Process ForkPoolWorker-37:\n",
            "Process ForkPoolWorker-9:\n",
            "Process ForkPoolWorker-5:\n",
            "Process ForkPoolWorker-29:\n",
            "Process ForkPoolWorker-14:\n",
            "Process ForkPoolWorker-25:\n",
            "Process ForkPoolWorker-2:\n",
            "Process ForkPoolWorker-21:\n",
            "Process ForkPoolWorker-16:\n",
            "Process ForkPoolWorker-36:\n",
            "Process ForkPoolWorker-7:\n",
            "Process ForkPoolWorker-39:\n",
            "Process ForkPoolWorker-28:\n",
            "Process ForkPoolWorker-33:\n",
            "Process ForkPoolWorker-6:\n",
            "Process ForkPoolWorker-13:\n",
            "Process ForkPoolWorker-10:\n",
            "Process ForkPoolWorker-12:\n",
            "Process ForkPoolWorker-26:\n",
            "Process ForkPoolWorker-20:\n",
            "Process ForkPoolWorker-19:\n",
            "Process ForkPoolWorker-40:\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExporting masks for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (cv=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCV_INDEX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexport_output_masks_IOU_02.py\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--exp_id\u001b[39m\u001b[38;5;124m'\u001b[39m, exp_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--cv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(CV_INDEX)]\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mrunpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSCRIPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__main__\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Verify outputs\u001b[39;00m\n\u001b[1;32m     27\u001b[0m mask_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DIR_OUTPUT, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput_Masks_*.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
            "File \u001b[0;32m~/.conda/envs/tensorflow-2.12/lib/python3.8/runpy.py:265\u001b[0m, in \u001b[0;36mrun_path\u001b[0;34m(path_name, init_globals, run_name)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(importer, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;129;01mor\u001b[39;00m is_NullImporter:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# Not a valid sys.path entry, so run the code directly\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# execfile() doesn't help as we want to allow compiled files\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     code, fname \u001b[38;5;241m=\u001b[39m _get_code_from_file(run_name, path_name)\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_module_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_globals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpkg_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpkg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# Finder is defined for path, so add it to\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# the start of sys.path\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, path_name)\n",
            "File \u001b[0;32m~/.conda/envs/tensorflow-2.12/lib/python3.8/runpy.py:97\u001b[0m, in \u001b[0;36m_run_module_code\u001b[0;34m(code, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _TempModule(mod_name) \u001b[38;5;28;01mas\u001b[39;00m temp_module, _ModifiedArgv0(fname):\n\u001b[1;32m     96\u001b[0m     mod_globals \u001b[38;5;241m=\u001b[39m temp_module\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m---> 97\u001b[0m     \u001b[43m_run_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod_globals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Copy the globals of the temporary module, as they\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# may be cleared when the temporary module goes away\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mod_globals\u001b[38;5;241m.\u001b[39mcopy()\n",
            "File \u001b[0;32m~/.conda/envs/tensorflow-2.12/lib/python3.8/runpy.py:87\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m(code, run_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n\u001b[1;32m     79\u001b[0m         pkg_name \u001b[38;5;241m=\u001b[39m mod_spec\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m     80\u001b[0m run_globals\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m mod_name,\n\u001b[1;32m     81\u001b[0m                    \u001b[38;5;18m__file__\u001b[39m \u001b[38;5;241m=\u001b[39m fname,\n\u001b[1;32m     82\u001b[0m                    __cached__ \u001b[38;5;241m=\u001b[39m cached,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m                    __package__ \u001b[38;5;241m=\u001b[39m pkg_name,\n\u001b[1;32m     86\u001b[0m                    __spec__ \u001b[38;5;241m=\u001b[39m mod_spec)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_globals\n",
            "File \u001b[0;32m~/nicole/code/SUNS_nicole/demo/mouse7_new/export_output_masks_IOU_02.py:120\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m(\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m~/nicole/code/SUNS_nicole/demo/mouse7_new/export_output_masks_IOU_02.py:96\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Use multiprocessing to match complete_segment's default useMP=True path\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool() \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m---> 96\u001b[0m     Masks, Masks_2, times_active, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43msuns_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir_video\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir_video\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mExp_ID\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_CNN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParams_pre\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParams_pre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParams_post\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParams_post\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Save MATLAB file as (Lx, Ly, n)\u001b[39;00m\n\u001b[1;32m    108\u001b[0m Masks_out \u001b[38;5;241m=\u001b[39m Masks\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m/gpfs/data/shohamlab/nicole/code/SUNS_nicole/suns/run_suns.py:114\u001b[0m, in \u001b[0;36msuns_batch\u001b[0;34m(dir_video, Exp_ID, filename_CNN, Params_pre, Params_post, batch_size_eval, useSF, useTF, useSNR, med_subtract, useWT, prealloc, display, useMP, p)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitialization time: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time_init\u001b[38;5;241m-\u001b[39mstart))\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# %% Actual processing starts after the video is loaded into memory\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# which is in the middle of \"preprocess_video\", represented by the output \"start\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# pre-processing including loading data\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m video_input, start \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mExp_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mParams_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43museSF\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43museSF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43museTF\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43museTF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43museSNR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43museSNR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmed_subtract\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmed_subtract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprealloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprealloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display:\n\u001b[1;32m    117\u001b[0m     end_pre \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
            "File \u001b[0;32m/gpfs/data/shohamlab/nicole/code/SUNS_nicole/suns/PreProcessing/preprocessing_functions.py:516\u001b[0m, in \u001b[0;36mpreprocess_video\u001b[0;34m(dir_video, Exp_ID, Params, dir_network_input, useSF, useTF, useSNR, med_subtract, prealloc, display)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nframes): \u001b[38;5;66;03m# use this one to save memory\u001b[39;00m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m         bb[t, :rows, :cols] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mh5_file\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;66;03m# Handle compressed chunk read failures by repeating the previous frame (or zeros for t==0)\u001b[39;00m\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/.conda/envs/tensorflow-2.12/lib/python3.8/site-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Export Output_Masks_<exp_id>.mat for all videos using trained model/params\n",
        "import os, sys, glob, runpy\n",
        "from pprint import pprint\n",
        "from suns import config as suns_config\n",
        "\n",
        "# Discover directories from config\n",
        "exp_set = suns_config.ACTIVE_EXP_SET\n",
        "DIR_VIDEO = suns_config.DATAFOLDER_SETS[exp_set]\n",
        "DIR_PARENT = os.path.join(DIR_VIDEO, suns_config.OUTPUT_FOLDER[exp_set])\n",
        "DIR_OUTPUT = os.path.join(DIR_PARENT, 'output_masks')\n",
        "os.makedirs(DIR_OUTPUT, exist_ok=True)\n",
        "\n",
        "# Choose which CV index to export with (adjust if needed)\n",
        "CV_INDEX = 0\n",
        "\n",
        "# Export for each experiment id\n",
        "list_Exp_ID = suns_config.EXP_ID_SETS[exp_set]\n",
        "SCRIPT = '/gpfs/home/bizzin01/nicole/code/SUNS_nicole/demo/mouse7_new/export_output_masks_IOU_02.py'\n",
        "print('Export script:', SCRIPT)\n",
        "\n",
        "for exp_id in list_Exp_ID:\n",
        "    print(f'Exporting masks for {exp_id} (cv={CV_INDEX})...')\n",
        "    sys.argv = ['export_output_masks_IOU_02.py', '--exp_id', exp_id, '--cv', str(CV_INDEX)]\n",
        "    runpy.run_path(SCRIPT, run_name='__main__')\n",
        "\n",
        "# Verify outputs\n",
        "mask_files = sorted(glob.glob(os.path.join(DIR_OUTPUT, 'Output_Masks_*.mat')))\n",
        "print(f'Found {len(mask_files)} mask files in {DIR_OUTPUT}')\n",
        "pprint(mask_files[:10])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TensorFlow 2.12",
      "language": "python",
      "name": "tensorflow-2.12"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
